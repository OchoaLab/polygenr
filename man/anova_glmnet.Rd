% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/anova_glmnet.R
\name{anova_glmnet}
\alias{anova_glmnet}
\title{Assign ANOVA type-II -log10 p-values to every submodel of a sparse \code{glmnet} model}
\usage{
anova_glmnet(beta, X, y, pcs = NULL)
}
\arguments{
\item{beta}{The matrix of coefficients (component \verb{$beta}) of the \code{glmnet} object.}

\item{X}{The genotype matrix.
Same as was used in \code{\link[=glmnet_pca]{glmnet_pca()}}.}

\item{y}{The trait vector.
Same as was used in \code{\link[=glmnet_pca]{glmnet_pca()}}.}

\item{pcs}{The PC (eigenvector) matrix (optional).
Same as was used in \code{\link[=glmnet_pca]{glmnet_pca()}}.
Unlike genotypes, PCs are not given p-values.}
}
\value{
A sparse matrix (class \code{dgCMatrix}) with the same dimensions as \code{beta}, containing type-II ANOVA -log10 p-values.
Zero coefficients (unselected variables) are assigned values of zero as well (to retain sparsity, imply p-values of 1).
For selected variables in each column, p-values are calculated using \code{\link[=anova2]{anova2()}}, see that for more details.
}
\description{
Given a sparse \code{glmnet} model (not ridge regression), here we assing ANOVA type-II -log10 p-values to every submodel obtained by varying the \code{lambda} penalty factor (i.e. each column of the \verb{$beta} component matrix of the \code{glmnet} object).
To achieve this, each set of selected loci is fit again to the original data without penalization.
}
\examples{
\dontrun{
scores <- anova_glmnet( beta, X, y, pcs )
}

}
\seealso{
\code{\link[=anova_glmnet_single]{anova_glmnet_single()}} for calculations on a single model (by default, approximately the best) instead of all models (all lambdas), which is much faster and generally recommended.

\code{\link[=anova_single]{anova_single()}} for scoring a model specified by locus indexes only.

\code{\link[=anova2]{anova2()}} for additional details and data restrictions.

\code{\link[=scores_glmnet]{scores_glmnet()}} for a different way of scoring/raking variants.
}
